<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NeuroTalkSignToText</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/ort.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        body { font-family: 'Inter', sans-serif; background-color: #f8fafc; }
        .gradient-bg { background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%); }
        .video-container { 
            position: relative; 
            padding-bottom: 56.25%; 
            height: 0; 
            overflow: hidden; 
            border-radius: 12px; 
            background-color: #000; 
        }
        .video-container video, .video-container canvas { 
            position: absolute; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            object-fit: cover; 
        }
        .processing-overlay { 
            position: absolute; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            background: rgba(0,0,0,0.7); 
            display: none; 
            justify-content: center; 
            align-items: center; 
            color: white; 
        }
        .camera-error { display: none; color: #ef4444; font-size: 0.875rem; margin-top: 0.5rem; }
    </style>
</head>
<body>
    <header class="gradient-bg text-white">
        <div class="container mx-auto px-4 py-8">
            <div class="flex justify-between items-center">
                <div class="flex items-center space-x-2">
                    <i class="fas fa-hands-helping text-3xl"></i>
                    <h1 class="text-2xl font-bold">NeuroTalkSignToText</h1>
                </div>
            </div>
            <div class="mt-16 mb-12 text-center">
                <h2 class="text-4xl md:text-5xl font-bold mb-4">Переводчик жестовых языков</h2>
                <p class="text-xl md:text-2xl max-w-3xl mx-auto">Реальное распознавание РЖЯ и ASL</p>
            </div>
        </div>
    </header>

    <main class="container mx-auto px-4 py-12 -mt-10">
        <div class="bg-white rounded-xl shadow-xl overflow-hidden">
            <div class="grid md:grid-cols-2 gap-8 p-8">
                <div>
                    <div class="mb-6">
                        <div class="flex justify-between items-center mb-4">
                            <div class="flex items-center space-x-3">
                                <select id="language-select" class="bg-gray-100 border border-gray-300 rounded-full py-1 px-4 pr-8 text-sm">
                                    <option value="RSL">Русский (РЖЯ)</option>
                                    <option value="ASL">Американский (ASL)</option>
                                </select>
                                <button id="switch-camera" class="text-gray-700 hover:text-indigo-600 transition" title="Сменить камеру">
                                    <i class="fas fa-camera-retro"></i>
                                </button>
                            </div>
                            <div class="flex items-center space-x-2 text-sm">
                                <span>Порог уверенности:</span>
                                <input type="range" id="confidence-threshold" min="0" max="100" value="70" class="w-24 accent-indigo-600">
                                <span id="threshold-value">70%</span>
                            </div>
                        </div>
                        <div class="video-container">
                            <video id="input-video" autoplay muted playsinline class="hidden"></video>
                            <canvas id="processing-canvas"></canvas>
                            <div id="video-placeholder" class="absolute inset-0 flex flex-col items-center justify-center bg-gray-100">
                                <i class="fas fa-video-slash text-4xl mb-4 text-gray-400"></i>
                                <button id="start-camera-btn" class="bg-indigo-600 text-white px-6 py-3 rounded-lg hover:bg-indigo-700 transition">
                                    Активировать камеру
                                </button>
                                <div id="camera-error" class="camera-error mt-2"></div>
                            </div>
                            <div id="processing-overlay" class="processing-overlay">
                                <div class="text-center">
                                    <div class="animate-spin rounded-full h-8 w-8 border-b-2 border-white mx-auto"></div>
                                    <p class="mt-2">Обработка жеста...</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div>
                    <div class="mb-6">
                        <div class="flex justify-between items-center mb-4">
                            <label class="font-medium text-gray-700">Результаты</label>
                            <div class="flex space-x-3">
                                <button id="copy-btn" class="text-gray-500 hover:text-indigo-600"><i class="fas fa-copy"></i></button>
                                <button id="clear-btn" class="text-gray-500 hover:text-indigo-600"><i class="fas fa-trash"></i></button>
                            </div>
                        </div>
                        <div class="bg-gray-50 p-4 rounded-lg h-96 overflow-y-auto">
                            <div id="output" class="space-y-2"></div>
                            <div id="confidence" class="mt-4 hidden">
                                <div class="flex justify-between mb-1 text-sm">
                                    <span>Уверенность:</span>
                                    <span id="confidence-value">0%</span>
                                </div>
                                <div class="h-2 bg-gray-200 rounded-full">
                                    <div id="confidence-bar" class="h-2 bg-indigo-600 rounded-full transition-all" style="width: 0%"></div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const MODEL_CONFIG = {
                RSL: {
                    path: 'models/rsl_model.onnx',
                    labels: 'labels/RSL_class_list.txt',
                    inputName: 'actual_input_1',
                    outputName: 'output',
                    inputShape: [1, 3, 32, 224, 224],
                    frameBufferSize: 32,
                    targetFPS: 20,
                    resolution: 224
                },
                ASL: {
                    path: 'models/asl_model.onnx',
                    labels: 'labels/asl_classes.txt',
                    inputName: 'input',
                    outputName: 'output',
                    inputShape: [1, 1, 28, 28],
                    targetFPS: 15,
                    resolution: 28
                }
            };

            let currentModel = null;
            let currentLabels = [];
            let isProcessing = false;
            let videoStream = null;
            let currentModelType = 'RSL';
            let confidenceThreshold = 0.7;
            let frameBuffer = [];
            let cameras = [];
            let currentCameraId = '';
            let isProcessingFrame = false;
            let lastFrameTime = 0;

            const elements = {
                video: document.getElementById('input-video'),
                canvas: document.getElementById('processing-canvas'),
                startBtn: document.getElementById('start-camera-btn'),
                output: document.getElementById('output'),
                processing: document.getElementById('processing-overlay'),
                confidence: document.getElementById('confidence'),
                confidenceValue: document.getElementById('confidence-value'),
                confidenceBar: document.getElementById('confidence-bar'),
                threshold: document.getElementById('confidence-threshold'),
                thresholdValue: document.getElementById('threshold-value'),
                switchCamera: document.getElementById('switch-camera'),
                languageSelect: document.getElementById('language-select'),
                cameraError: document.getElementById('camera-error')
            };

            // Инициализация камер
            async function initCameras() {
                try {
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    cameras = devices.filter(device => device.kind === 'videoinput');
                    if (cameras.length > 0) currentCameraId = cameras[0].deviceId;
                } catch (error) {
                    showCameraError('Ошибка доступа к списку камер');
                }
            }

            // Загрузка меток классов
            async function loadLabels(modelType) {
                try {
                    const response = await fetch(MODEL_CONFIG[modelType].labels);
                    const text = await response.text();
                    return text.split('\n')
                        .map(line => line.match(/(\d+)\s+([\wа-яё]+)/i)?.[2]?.trim())
                        .filter(Boolean);
                } catch (error) {
                    showCameraError('Ошибка загрузки меток');
                    return [];
                }
            }

            // Инициализация модели
            async function initializeModel(modelType) {
                try {
                    showProcessing('Загрузка модели...');
                    currentLabels = await loadLabels(modelType);
                    if (currentLabels.length === 0) throw new Error('Неверный формат меток');
                    
                    currentModel = await ort.InferenceSession.create(MODEL_CONFIG[modelType].path);
                    console.log(`${modelType} модель загружена`);
                    return true;
                } catch (error) {
                    showCameraError(`Ошибка: ${error.message}`);
                    return false;
                } finally {
                    hideProcessing();
                }
            }

            // Предобработка кадра
            function preprocessFrame() {
                const config = MODEL_CONFIG[currentModelType];
                const ctx = elements.canvas.getContext('2d', { willReadFrequently: true });
                
                // Настройка канваса
                elements.canvas.width = config.resolution;
                elements.canvas.height = config.resolution;
                ctx.imageSmoothingQuality = 'high';
                ctx.drawImage(elements.video, 0, 0, config.resolution, config.resolution);

                // Обработка для РЖЯ
                if (currentModelType === 'RSL') {
                    const imageData = ctx.getImageData(0, 0, config.resolution, config.resolution);
                    const frameData = new Float32Array(3 * config.resolution ** 2);

                    for (let i = 0; i < imageData.data.length; i += 4) {
                        const idx = i/4;
                        frameData[idx] = imageData.data[i] / 255; // R
                        frameData[idx + config.resolution**2] = imageData.data[i+1] / 255; // G
                        frameData[idx + 2*config.resolution**2] = imageData.data[i+2] / 255; // B
                    }

                    frameBuffer.push(frameData);
                    if (frameBuffer.length > config.frameBufferSize) frameBuffer.shift();

                    const tensorData = new Float32Array(config.inputShape.reduce((a,b) => a*b));
                    let offset = 0;
                    for (let i = 0; i < config.frameBufferSize; i++) {
                        const frame = frameBuffer[i] || new Float32Array(3*config.resolution**2).fill(0);
                        tensorData.set(frame, offset);
                        offset += frame.length;
                    }
                    return new ort.Tensor('float32', tensorData, config.inputShape);
                } 
                // Обработка для ASL
                else {
                    const imageData = ctx.getImageData(0, 0, config.resolution, config.resolution);
                    const data = new Float32Array(config.resolution ** 2);
                    
                    for (let i = 0; i < imageData.data.length; i += 4) {
                        data[i/4] = (imageData.data[i] + imageData.data[i+1] + imageData.data[i+2]) / (3*255);
                    }
                    return new ort.Tensor('float32', data, config.inputShape);
                }
            }

            // Обработка результатов
            function handlePredictions(predictions) {
                if (!currentLabels?.length) return;

                const scores = Array.from(predictions.data);
                const probabilities = softmax(scores);
                const maxProb = Math.max(...probabilities);
                const predIndex = probabilities.indexOf(maxProb);
                const label = currentLabels[predIndex] || 'Неизвестно';

                if (maxProb >= confidenceThreshold) {
                    const entry = document.createElement('div');
                    entry.className = 'p-2 bg-white rounded shadow-sm';
                    entry.innerHTML = `
                        <span class="text-gray-500 text-sm">${new Date().toLocaleTimeString()}</span>
                        <span class="font-medium ml-2">${label}</span>
                        <span class="text-indigo-500 ml-2">${(maxProb * 100).toFixed(1)}%</span>
                    `;
                    elements.output.prepend(entry);
                }

                elements.confidenceValue.textContent = `${(maxProb * 100).toFixed(1)}%`;
                elements.confidenceBar.style.width = `${(maxProb * 100).toFixed(1)}%`;
                elements.confidence.classList.remove('hidden');
            }

            // Основной цикл обработки
            async function processFrame() {
                if (!isProcessing || !currentModel || isProcessingFrame) return;

                const now = performance.now();
                const config = MODEL_CONFIG[currentModelType];
                if (now - lastFrameTime < 1000/config.targetFPS) {
                    requestAnimationFrame(processFrame);
                    return;
                }

                isProcessingFrame = true;
                lastFrameTime = now;

                try {
                    const inputTensor = preprocessFrame();
                    const feeds = { [config.inputName]: inputTensor };
                    const results = await currentModel.run(feeds);
                    handlePredictions(results[config.outputName]);
                } catch (error) {
                    console.error('Ошибка обработки:', error);
                } finally {
                    isProcessingFrame = false;
                    requestAnimationFrame(processFrame);
                }
            }

            // Вспомогательные функции
            function softmax(arr) {
                const exp = arr.map(x => Math.exp(x));
                const sum = exp.reduce((a,b) => a + b);
                return exp.map(x => x/sum);
            }

            async function startCamera(deviceId = '') {
                try {
                    const config = MODEL_CONFIG[currentModelType];
                    const constraints = {
                        video: {
                            deviceId: deviceId ? { exact: deviceId } : undefined,
                            width: { ideal: config.resolution },
                            height: { ideal: config.resolution },
                            frameRate: { ideal: config.targetFPS }
                        }
                    };

                    videoStream = await navigator.mediaDevices.getUserMedia(constraints);
                    elements.video.srcObject = videoStream;
                    elements.video.classList.remove('hidden');
                    document.getElementById('video-placeholder').classList.add('hidden');
                    elements.cameraError.textContent = '';

                    if (await initializeModel(currentModelType)) {
                        isProcessing = true;
                        requestAnimationFrame(processFrame);
                    }
                } catch (error) {
                    handleCameraError(error);
                }
            }

            function handleCameraError(error) {
                elements.cameraError.textContent = error.name === 'NotAllowedError' 
                    ? 'Требуется доступ к камере' 
                    : error.message;
                elements.cameraError.classList.remove('hidden');
                document.getElementById('video-placeholder').classList.remove('hidden');
                elements.video.classList.add('hidden');
            }

            function showProcessing(message) {
                elements.processing.querySelector('p').textContent = message;
                elements.processing.style.display = 'flex';
            }

            function hideProcessing() {
                elements.processing.style.display = 'none';
            }

            // Обработчики событий
            elements.startBtn.addEventListener('click', () => startCamera());
            elements.switchCamera.addEventListener('click', async () => {
                if (cameras.length < 2) return;
                currentCameraId = cameras[(cameras.findIndex(c => c.deviceId === currentCameraId) + 1 % cameras.length].deviceId;
                if (videoStream) videoStream.getTracks().forEach(t => t.stop());
                await startCamera(currentCameraId);
            });
            elements.languageSelect.addEventListener('change', async function() {
                currentModelType = this.value;
                frameBuffer = [];
                if (videoStream) videoStream.getTracks().forEach(t => t.stop());
                await startCamera(currentCameraId);
            });
            elements.threshold.addEventListener('input', e => {
                confidenceThreshold = e.target.value / 100;
                elements.thresholdValue.textContent = `${e.target.value}%`;
            });
            elements.clearBtn.addEventListener('click', () => {
                elements.output.innerHTML = '<div class="text-gray-400 text-center py-4">История очищена</div>';
                elements.confidence.classList.add('hidden');
            });
            elements.copyBtn.addEventListener('click', () => {
                const text = Array.from(elements.output.children).reverse().map(e => e.textContent).join('\n');
                navigator.clipboard.writeText(text).then(() => {
                    const icon = elements.copyBtn.querySelector('i');
                    icon.className = 'fas fa-check text-green-500';
                    setTimeout(() => icon.className = 'fas fa-copy', 2000);
                });
            });

            // Инициализация
            initCameras();
        });
    </script>
</body>
</html>
