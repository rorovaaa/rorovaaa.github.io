<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NeuroTalkSignToText - Переводчик жестовых языков</title>
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/ort.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <meta http-equiv="Content-Security-Policy" 
          content="default-src 'self' https://telegram.org; 
                   script-src 'self' https://cdn.tailwindcss.com https://cdn.jsdelivr.net https://cdnjs.cloudflare.com 'unsafe-eval'; 
                   connect-src 'self' blob:;
                   media-src 'self' blob:;
                   style-src 'self' https://fonts.googleapis.com 'unsafe-inline';
                   font-src 'self' https://fonts.gstatic.com">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        body { 
            font-family: 'Inter', sans-serif; 
            background-color: #f8fafc; 
        }
        .gradient-bg { 
            background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%); 
        }
        .video-container { 
            position: relative; 
            padding-bottom: 56.25%; 
            height: 0; 
            overflow: hidden; 
            border-radius: 12px; 
            background-color: #000; 
        }
        .video-container video, 
        .video-container canvas { 
            position: absolute; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            object-fit: cover; 
        }
        .processing-overlay { 
            position: absolute; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            background: rgba(0,0,0,0.7); 
            display: none; 
            justify-content: center; 
            align-items: center; 
            color: white; 
        }
        #processing-video,
        #processing-canvas {
            display: none;
        }
    </style>
</head>
<body>
    <header class="gradient-bg text-white">
        <div class="container mx-auto px-4 py-8">
            <div class="flex justify-between items-center">
                <div class="flex items-center space-x-2">
                    <i class="fas fa-hands-helping text-3xl"></i>
                    <h1 class="text-2xl font-bold">NeuroTalkSignToText</h1>
                </div>
            </div>
            <div class="mt-16 mb-12 text-center">
                <h2 class="text-4xl md:text-5xl font-bold mb-4">Переводчик жестовых языков</h2>
                <p class="text-xl md:text-2xl max-w-3xl mx-auto">
                    Реальное распознавание РЖЯ и ASL в реальном времени
                </p>
            </div>
        </div>
    </header>

    <main class="container mx-auto px-4 py-12 -mt-10">
        <div class="bg-white rounded-xl shadow-xl overflow-hidden">
            <div class="grid md:grid-cols-2 gap-8 p-8">
                <div>
                    <div class="mb-6">
                        <div class="flex justify-between items-center mb-4">
                            <div class="flex items-center space-x-3">
                                <select id="language-select" class="bg-gray-100 border border-gray-300 rounded-full py-1 px-4 pr-8 text-sm">
                                    <option value="RSL">Русский (РЖЯ)</option>
                                    <option value="ASL">Американский (ASL)</option>
                                </select>
                                <button id="switch-camera" class="text-gray-700 hover:text-indigo-600 transition" title="Сменить камеру">
                                    <i class="fas fa-camera-retro"></i>
                                </button>
                            </div>
                            <div class="flex items-center space-x-2 text-sm">
                                <span>Порог уверенности:</span>
                                <input type="range" id="confidence-threshold" min="0" max="100" value="70" class="w-24 accent-indigo-600">
                                <span id="threshold-value">70%</span>
                            </div>
                        </div>
                        <div class="video-container">
                            <!-- Видео для отображения пользователю -->
                            <video id="user-video" autoplay muted playsinline class="hidden"></video>
                            
                            <!-- Скрытые элементы для обработки -->
                            <video id="processing-video" autoplay muted playsinline class="hidden"></video>
                            <canvas id="processing-canvas"></canvas>
                            
                            <div id="video-placeholder" class="absolute inset-0 flex flex-col items-center justify-center bg-gray-100">
                                <i class="fas fa-video-slash text-4xl mb-4 text-gray-400"></i>
                                <button id="start-camera-btn" class="bg-indigo-600 text-white px-6 py-3 rounded-lg hover:bg-indigo-700 transition">
                                    Активировать камеру
                                </button>
                            </div>
                            <div id="processing-overlay" class="processing-overlay">
                                <div class="text-center">
                                    <div class="animate-spin rounded-full h-8 w-8 border-b-2 border-white mx-auto"></div>
                                    <p class="mt-2">Обработка жеста...</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div>
                    <div class="mb-6">
                        <div class="flex justify-between items-center mb-4">
                            <label class="font-medium text-gray-700">Результаты распознавания</label>
                            <div class="flex space-x-3">
                                <button id="copy-btn" class="text-gray-500 hover:text-indigo-600">
                                    <i class="fas fa-copy"></i>
                                </button>
                                <button id="clear-btn" class="text-gray-500 hover:text-indigo-600">
                                    <i class="fas fa-trash"></i>
                                </button>
                            </div>
                        </div>
                        <div class="bg-gray-50 p-4 rounded-lg h-96 overflow-y-auto">
                            <div id="output" class="space-y-2"></div>
                            <div id="confidence" class="mt-4 hidden">
                                <div class="flex justify-between mb-1 text-sm">
                                    <span>Уверенность:</span>
                                    <span id="confidence-value">0%</span>
                                </div>
                                <div class="h-2 bg-gray-200 rounded-full">
                                    <div id="confidence-bar" class="h-2 bg-indigo-600 rounded-full transition-all" style="width: 0%"></div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            Telegram.WebApp.ready();
            Telegram.WebApp.expand();

            const MODEL_CONFIG = {
                RSL: {
                    path: 'models/rsl_model.onnx',
                    labels: 'labels/RSL_class_list.txt',
                    inputName: 'actual_input_1',
                    inputShape: [1, 3, 32, 224, 224],
                    frameBufferSize: 32
                },
                ASL: {
                    path: 'models/asl_model.onnx',
                    labels: 'labels/h5_classes.txt',
                    inputName: 'input',
                    inputShape: [1, 1, 28, 28]
                }
            };

            let currentModel = null;
            let currentLabels = [];
            let isProcessing = false;
            let userStream = null;
            let processingStream = null;
            let currentModelType = 'RSL';
            let confidenceThreshold = 0.7;
            let frameBuffer = [];
            let cameras = [];
            let currentCameraId = '';

            const elements = {
                userVideo: document.getElementById('user-video'),
                processingVideo: document.getElementById('processing-video'),
                processingCanvas: document.getElementById('processing-canvas'),
                startBtn: document.getElementById('start-camera-btn'),
                output: document.getElementById('output'),
                processing: document.getElementById('processing-overlay'),
                confidence: document.getElementById('confidence'),
                confidenceValue: document.getElementById('confidence-value'),
                confidenceBar: document.getElementById('confidence-bar'),
                threshold: document.getElementById('confidence-threshold'),
                thresholdValue: document.getElementById('threshold-value'),
                switchCamera: document.getElementById('switch-camera'),
                languageSelect: document.getElementById('language-select')
            };

            async function initCameras() {
                if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
                    Telegram.WebApp.showAlert("Ваш браузер не поддерживает доступ к устройствам");
                    return;
                }

                try {
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    cameras = devices.filter(device => device.kind === 'videoinput');
                    if (cameras.length > 0) {
                        currentCameraId = cameras[0].deviceId;
                    }
                } catch (error) {
                    console.error('Ошибка получения списка камер:', error);
                    Telegram.WebApp.showAlert("Ошибка доступа к камерам");
                }
            }

            async function loadLabels(modelType) {
                try {
                    const response = await fetch(MODEL_CONFIG[modelType].labels);
                    const text = await response.text();
                    return modelType === 'RSL'
                        ? text.split('\n').map(line => line.split('\t')[1]?.trim() || 'Unknown')
                        : text.split('\n').map(line => line.split(' ')[1]?.trim() || 'Unknown');
                } catch (error) {
                    console.error('Ошибка загрузки меток:', error);
                    Telegram.WebApp.showAlert("Ошибка загрузки меток классов");
                    return [];
                }
            }

            async function initializeModel(modelType) {
                try {
                    elements.processing.style.display = 'flex';
                    currentLabels = await loadLabels(modelType);
                    
                    if (currentLabels.length === 0) {
                        throw new Error('Не удалось загрузить метки классов');
                    }

                    currentModel = await ort.InferenceSession.create(MODEL_CONFIG[modelType].path);
                    console.log(`${modelType} модель успешно загружена`);
                    return true;
                } catch (error) {
                    console.error(`Ошибка загрузки модели ${modelType}:`, error);
                    Telegram.WebApp.showAlert(`Ошибка загрузки модели: ${error.message}`);
                    return false;
                } finally {
                    elements.processing.style.display = 'none';
                }
            }

            function preprocessFrame() {
                const config = MODEL_CONFIG[currentModelType];
                const ctx = elements.processingCanvas.getContext('2d');

                // Настройка размеров canvas в зависимости от модели
                const targetWidth = currentModelType === 'RSL' ? 224 : 28;
                const targetHeight = currentModelType === 'RSL' ? 224 : 28;

                elements.processingCanvas.width = targetWidth;
                elements.processingCanvas.height = targetHeight;

                // Отрисовка кадра из processing-video в canvas
                ctx.drawImage(
                    elements.processingVideo,
                    0, 0, elements.processingVideo.videoWidth, elements.processingVideo.videoHeight,
                    0, 0, targetWidth, targetHeight
                );

                if (currentModelType === 'RSL') {
                    const imageData = ctx.getImageData(0, 0, targetWidth, targetHeight);
                    const frameData = new Float32Array(3 * targetWidth * targetHeight);

                    for (let i = 0; i < imageData.data.length; i += 4) {
                        frameData[i / 4] = imageData.data[i] / 255;
                        frameData[i / 4 + targetWidth * targetHeight] = imageData.data[i + 1] / 255;
                        frameData[i / 4 + 2 * targetWidth * targetHeight] = imageData.data[i + 2] / 255;
                    }

                    frameBuffer.push(frameData);
                    if (frameBuffer.length > config.frameBufferSize) {
                        frameBuffer.shift();
                    }

                    const tensorData = new Float32Array(config.inputShape.reduce((a, b) => a * b, 1));
                    let offset = 0;
                    for (let i = 0; i < config.frameBufferSize; i++) {
                        const frame = frameBuffer[i] || new Float32Array(3 * targetWidth * targetHeight).fill(0);
                        tensorData.set(frame, offset);
                        offset += frame.length;
                    }

                    return new ort.Tensor('float32', tensorData, config.inputShape);
                } else {
                    const imageData = ctx.getImageData(0, 0, targetWidth, targetHeight);
                    const data = new Float32Array(1 * 1 * targetWidth * targetHeight);

                    for (let i = 0; i < imageData.data.length; i += 4) {
                        const grayValue = (imageData.data[i] + imageData.data[i + 1] + imageData.data[i + 2]) / 3;
                        data[i / 4] = grayValue / 255;
                    }

                    return new ort.Tensor('float32', data, config.inputShape);
                }
            }

            function handlePredictions(predictions) {
                const scores = Array.from(predictions.data);
                const softmax = scores.map(x => Math.exp(x));
                const sum = softmax.reduce((a, b) => a + b, 0);
                const probabilities = softmax.map(x => x / sum);

                const maxProbability = Math.max(...probabilities);
                const predictedIndex = probabilities.indexOf(maxProbability);

                if (maxProbability >= confidenceThreshold) {
                    const entry = document.createElement('div');
                    entry.className = 'p-2 bg-white rounded shadow-sm';
                    entry.innerHTML = `
                        <span class="text-gray-500 text-sm">${new Date().toLocaleTimeString()}</span>
                        <span class="font-medium ml-2">${currentLabels[predictedIndex]}</span>
                        <span class="text-indigo-500 ml-2">${(maxProbability * 100).toFixed(1)}%</span>
                    `;
                    elements.output.prepend(entry);
                }

                elements.confidenceValue.textContent = `${(maxProbability * 100).toFixed(1)}%`;
                elements.confidenceBar.style.width = `${(maxProbability * 100).toFixed(1)}%`;
                elements.confidence.classList.remove('hidden');
            }

            async function processFrame() {
                if (!isProcessing || !currentModel) return;

                try {
                    const inputTensor = preprocessFrame();
                    const results = await currentModel.run({
                        [MODEL_CONFIG[currentModelType].inputName]: inputTensor
                    });
                    handlePredictions(results[Object.keys(results)[0]]);
                } catch (error) {
                    console.error('Ошибка обработки кадра:', error);
                }
                requestAnimationFrame(processFrame);
            }

            async function startCamera(deviceId = '') {
                try {
                    const permission = await Telegram.WebApp.requestPermission('camera');
                    
                    if (permission !== 'granted') {
                        Telegram.WebApp.showAlert('Для работы приложения требуется доступ к камере!');
                        return;
                    }

                    // Настройки для пользовательского видео
                    const userConstraints = {
                        video: {
                            deviceId: deviceId ? { exact: deviceId } : undefined,
                            width: { ideal: 1280 },
                            height: { ideal: 720 },
                            facingMode: 'user'
                        }
                    };

                    // Настройки для обработки видео
                    const processingConstraints = {
                        video: {
                            deviceId: deviceId ? { exact: deviceId } : undefined,
                            width: { ideal: currentModelType === 'RSL' ? 224 : 28 },
                            height: { ideal: currentModelType === 'RSL' ? 224 : 28 },
                            frameRate: { ideal: 30 }
                        }
                    };

                    // Остановка предыдущих потоков
                    if (userStream) userStream.getTracks().forEach(track => track.stop());
                    if (processingStream) processingStream.getTracks().forEach(track => track.stop());

                    // Запуск двух видеопотоков
                    userStream = await navigator.mediaDevices.getUserMedia(userConstraints);
                    processingStream = await navigator.mediaDevices.getUserMedia(processingConstraints);

                    // Отображение пользовательского видео
                    elements.userVideo.srcObject = userStream;
                    elements.userVideo.classList.remove('hidden');
                    
                    // Подключение потока для обработки
                    elements.processingVideo.srcObject = processingStream;
                    
                    document.getElementById('video-placeholder').classList.add('hidden');

                    if (await initializeModel(currentModelType)) {
                        isProcessing = true;
                        processFrame();
                    }
                } catch (error) {
                    console.error('Ошибка доступа к камере:', error);
                    Telegram.WebApp.showAlert(`Ошибка: ${error.message}`);
                }
            }

            elements.startBtn.addEventListener('click', async () => {
                await startCamera();
            });

            elements.switchCamera.addEventListener('click', async () => {
                if (cameras.length < 2) return;
                
                const currentIndex = cameras.findIndex(camera => camera.deviceId === currentCameraId);
                const newIndex = (currentIndex + 1) % cameras.length;
                currentCameraId = cameras[newIndex].deviceId;

                await startCamera(currentCameraId);
            });

            elements.languageSelect.addEventListener('change', async function() {
                isProcessing = false;
                currentModelType = this.value;
                frameBuffer = [];

                await startCamera(currentCameraId);
            });

            elements.threshold.addEventListener('input', (event) => {
                confidenceThreshold = event.target.value / 100;
                elements.thresholdValue.textContent = `${event.target.value}%`;
            });

            elements.clearBtn.addEventListener('click', () => {
                elements.output.innerHTML = '<div class="text-gray-400 text-center py-4">История очищена</div>';
                elements.confidence.classList.add('hidden');
            });

            elements.copyBtn.addEventListener('click', () => {
                const text = Array.from(elements.output.children)
                    .map(element => element.textContent)
                    .reverse()
                    .join('\n');
                
                navigator.clipboard.writeText(text)
                    .then(() => {
                        const icon = elements.copyBtn.querySelector('i');
                        icon.className = 'fas fa-check text-green-500';
                        setTimeout(() => {
                            icon.className = 'fas fa-copy';
                        }, 2000);
                    });
            });

            Telegram.WebApp.onEvent('viewportChanged', () => {
                Telegram.WebApp.expand();
            });

            initCameras();
        });
    </script>
</body>
</html>
